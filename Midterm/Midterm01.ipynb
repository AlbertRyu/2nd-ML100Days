{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import date\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import KFold, train_test_split, StratifiedKFold, cross_val_score, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression, LinearRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, GradientBoostingRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import log_loss, roc_auc_score, auc, roc_curve, accuracy_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from mlxtend.classifier import StackingClassifier\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "DATA_ROOT = \"../data/ml100marathon-02-01/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data to df\n",
    "or_dfoff = pd.read_csv(os.path.join(DATA_ROOT,'train_offline.csv'))\n",
    "or_dftest = pd.read_csv(os.path.join(DATA_ROOT,'test_offline.csv'))\n",
    "# or_dfsample = pd.read_csv(os.path.join(DATA_ROOT,'sample_submission.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特徵分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_id</th>\n",
       "      <th>Merchant_id</th>\n",
       "      <th>Coupon_id</th>\n",
       "      <th>Discount_rate</th>\n",
       "      <th>Distance</th>\n",
       "      <th>Date_received</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1439408</td>\n",
       "      <td>2632</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20160217.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1439408</td>\n",
       "      <td>2632</td>\n",
       "      <td>8591.0</td>\n",
       "      <td>20:1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20160217.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1439408</td>\n",
       "      <td>2632</td>\n",
       "      <td>1078.0</td>\n",
       "      <td>20:1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20160319.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1832624</td>\n",
       "      <td>3381</td>\n",
       "      <td>7610.0</td>\n",
       "      <td>200:20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20160429.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2029232</td>\n",
       "      <td>3381</td>\n",
       "      <td>11951.0</td>\n",
       "      <td>200:20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160129.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   User_id  Merchant_id  Coupon_id Discount_rate  Distance  Date_received  \\\n",
       "0  1439408         2632        NaN           NaN       0.0            NaN   \n",
       "1  1439408         2632     8591.0          20:1       0.0     20160217.0   \n",
       "2  1439408         2632     1078.0          20:1       0.0     20160319.0   \n",
       "3  1832624         3381     7610.0        200:20       0.0     20160429.0   \n",
       "4  2029232         3381    11951.0        200:20       1.0     20160129.0   \n",
       "\n",
       "         Date  \n",
       "0  20160217.0  \n",
       "1         NaN  \n",
       "2         NaN  \n",
       "3         NaN  \n",
       "4         NaN  "
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "or_dfoff.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06033569157620371\n",
      "[[0.63134375]\n",
      " [0.37260625]\n",
      " [0.28323559]\n",
      " [0.2422437 ]\n",
      " [0.2193189 ]\n",
      " [0.20232873]\n",
      " [0.19002336]\n",
      " [0.1745231 ]\n",
      " [0.17344513]\n",
      " [0.16110196]\n",
      " [0.10851705]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.10919976])"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "null_value = or_dfoff[or_dfoff['Distance'].isnull()]['Date'].isna().value_counts()\n",
    "distance_na_buy_p = null_value[0]/null_value.sum()\n",
    "print(buy_p)\n",
    "\n",
    "x = []\n",
    "y = []\n",
    "\n",
    "for i in range(0,11):\n",
    "    value_series = or_dfoff[or_dfoff['Distance']==i]['Date'].isna().value_counts()\n",
    "    prop = value_series[0]/value_series.sum()\n",
    "    x.append(i)\n",
    "    y.append(prop)\n",
    "\n",
    "X = np.array(x).reshape(-1,1)\n",
    "Y = np.array(y).reshape(-1,1)\n",
    "T = np.array([10]).reshape(-1,1)\n",
    "print(Y)\n",
    "\n",
    "e = GradientBoostingRegressor()\n",
    "e.fit(X, Y)\n",
    "pred = e.predict(T)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x22b25e7fc88>"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特徵轉換 function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trans_id_to_string(df):\n",
    "    df = df.copy()\n",
    "    df['USER_ID'] = df['User_id'].astype('str')\n",
    "    df['MERCHANT_ID'] = df['Merchant_id'].astype('str')\n",
    "    df['COUPON_ID'] = df['Coupon_id'].apply(trans_coupon_id)\n",
    "    return df\n",
    "\n",
    "def trans_coupon_id(value):\n",
    "    if np.isnan(value):\n",
    "        return 'None'\n",
    "    else:\n",
    "        return str(int(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert distance\n",
    "def convert_distance(df):\n",
    "    df = df.copy()\n",
    "    df.loc[df.Distance.isna(), \"Distance\"] = 10\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dfoff' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-3a0120cfbe5d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Check data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdfoff\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconvert_distance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdfoff\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mdfoff\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dfoff' is not defined"
     ]
    }
   ],
   "source": [
    "# Check data\n",
    "dfoff = convert_distance(dfoff)\n",
    "dfoff.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert discunt_rate\n",
    "def convert_rate(value):\n",
    "    if value == 'nan':\n",
    "        return 1.0\n",
    "    elif ':' in value:\n",
    "        values = value.split(':')\n",
    "        return 1.0 - float(values[1])/float(values[0])\n",
    "    else:\n",
    "        return float(value)\n",
    "\n",
    "def find_discount_type(value):\n",
    "    if value == 'nan':\n",
    "        return 'None'\n",
    "    elif ':' in value:\n",
    "        return '1'\n",
    "    else:\n",
    "        return '0'\n",
    "\n",
    "def find_discount_require(value):\n",
    "    if ':' in value:\n",
    "        values = value.split(':')\n",
    "        return int(values[0])\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def find_discount_off(value):\n",
    "    if ':' in value:\n",
    "        values = value.split(':')\n",
    "        return int(values[1])\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_id</th>\n",
       "      <th>Merchant_id</th>\n",
       "      <th>Coupon_id</th>\n",
       "      <th>Discount_rate</th>\n",
       "      <th>Distance</th>\n",
       "      <th>Date_received</th>\n",
       "      <th>Date</th>\n",
       "      <th>LABEL</th>\n",
       "      <th>DISCOUNT_RATE</th>\n",
       "      <th>DISCOUNT_TYPE</th>\n",
       "      <th>...</th>\n",
       "      <th>DISCOUNT_OFF</th>\n",
       "      <th>WEEKDAY</th>\n",
       "      <th>WEEKEND</th>\n",
       "      <th>WEEKDAY_1</th>\n",
       "      <th>WEEKDAY_2</th>\n",
       "      <th>WEEKDAY_3</th>\n",
       "      <th>WEEKDAY_4</th>\n",
       "      <th>WEEKDAY_5</th>\n",
       "      <th>WEEKDAY_6</th>\n",
       "      <th>WEEKDAY_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1439408</td>\n",
       "      <td>2632</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20160217.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1439408</td>\n",
       "      <td>2632</td>\n",
       "      <td>8591.0</td>\n",
       "      <td>20:1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20160217.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1439408</td>\n",
       "      <td>2632</td>\n",
       "      <td>1078.0</td>\n",
       "      <td>20:1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20160319.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1832624</td>\n",
       "      <td>3381</td>\n",
       "      <td>7610.0</td>\n",
       "      <td>200:20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20160429.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2029232</td>\n",
       "      <td>3381</td>\n",
       "      <td>11951.0</td>\n",
       "      <td>200:20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160129.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2223968</td>\n",
       "      <td>3381</td>\n",
       "      <td>9776.0</td>\n",
       "      <td>10:5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20160129.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>73611</td>\n",
       "      <td>2099</td>\n",
       "      <td>12034.0</td>\n",
       "      <td>100:10</td>\n",
       "      <td>99.0</td>\n",
       "      <td>20160207.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>163606</td>\n",
       "      <td>1569</td>\n",
       "      <td>5054.0</td>\n",
       "      <td>200:30</td>\n",
       "      <td>10.0</td>\n",
       "      <td>20160421.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.85</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>30</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3273056</td>\n",
       "      <td>4833</td>\n",
       "      <td>7802.0</td>\n",
       "      <td>200:20</td>\n",
       "      <td>10.0</td>\n",
       "      <td>20160130.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>94107</td>\n",
       "      <td>3381</td>\n",
       "      <td>7610.0</td>\n",
       "      <td>200:20</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20160412.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   User_id  Merchant_id  Coupon_id Discount_rate  Distance  Date_received  \\\n",
       "0  1439408         2632        NaN           NaN       0.0            NaN   \n",
       "1  1439408         2632     8591.0          20:1       0.0     20160217.0   \n",
       "2  1439408         2632     1078.0          20:1       0.0     20160319.0   \n",
       "3  1832624         3381     7610.0        200:20       0.0     20160429.0   \n",
       "4  2029232         3381    11951.0        200:20       1.0     20160129.0   \n",
       "5  2223968         3381     9776.0          10:5       2.0     20160129.0   \n",
       "6    73611         2099    12034.0        100:10      99.0     20160207.0   \n",
       "7   163606         1569     5054.0        200:30      10.0     20160421.0   \n",
       "8  3273056         4833     7802.0        200:20      10.0     20160130.0   \n",
       "9    94107         3381     7610.0        200:20       2.0     20160412.0   \n",
       "\n",
       "         Date  LABEL  DISCOUNT_RATE DISCOUNT_TYPE  ...  DISCOUNT_OFF  WEEKDAY  \\\n",
       "0  20160217.0     -1           1.00          None  ...             0      NaN   \n",
       "1         NaN      0           0.95             1  ...             1      3.0   \n",
       "2         NaN      0           0.95             1  ...             1      6.0   \n",
       "3         NaN      0           0.90             1  ...            20      5.0   \n",
       "4         NaN      0           0.90             1  ...            20      5.0   \n",
       "5         NaN      0           0.50             1  ...             5      5.0   \n",
       "6         NaN      0           0.90             1  ...            10      7.0   \n",
       "7         NaN      0           0.85             1  ...            30      4.0   \n",
       "8         NaN      0           0.90             1  ...            20      6.0   \n",
       "9         NaN      0           0.90             1  ...            20      2.0   \n",
       "\n",
       "   WEEKEND  WEEKDAY_1  WEEKDAY_2  WEEKDAY_3  WEEKDAY_4  WEEKDAY_5  WEEKDAY_6  \\\n",
       "0        0          0          0          0          0          0          0   \n",
       "1        0          0          0          1          0          0          0   \n",
       "2        1          0          0          0          0          0          1   \n",
       "3        1          0          0          0          0          1          0   \n",
       "4        1          0          0          0          0          1          0   \n",
       "5        1          0          0          0          0          1          0   \n",
       "6        1          0          0          0          0          0          0   \n",
       "7        0          0          0          0          1          0          0   \n",
       "8        1          0          0          0          0          0          1   \n",
       "9        0          0          1          0          0          0          0   \n",
       "\n",
       "   WEEKDAY_7  \n",
       "0          0  \n",
       "1          0  \n",
       "2          0  \n",
       "3          0  \n",
       "4          0  \n",
       "5          0  \n",
       "6          1  \n",
       "7          0  \n",
       "8          0  \n",
       "9          0  \n",
       "\n",
       "[10 rows x 21 columns]"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check data\n",
    "dfoff['DISCOUNT_RATE'] = dfoff['Discount_rate'].astype('str').apply(convert_rate)\n",
    "dfoff['DISCOUNT_TYPE'] = dfoff['Discount_rate'].astype('str').apply(find_discount_type)\n",
    "dfoff['DISCOUNT_REQUIRE'] = dfoff['Discount_rate'].astype('str').apply(find_discount_require)\n",
    "dfoff['DISCOUNT_OFF'] = dfoff['Discount_rate'].astype('str').apply(find_discount_off)\n",
    "dfoff.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Date_received to weekday\n",
    "def expand_date_received(df):\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Year\n",
    "    df['YEAR'] = df['Date_received'].apply(get_year)\n",
    "    \n",
    "    # Month\n",
    "    df['MONTH'] = df['Date_received'].apply(get_month)\n",
    "    \n",
    "    # Day\n",
    "    df['DAY'] = df['Date_received'].apply(get_day)\n",
    "    \n",
    "    # Weekday\n",
    "    df['WEEKDAY'] = df['Date_received'].apply(get_weekday)\n",
    "    \n",
    "    # Weekend\n",
    "    df['WEEKEND'] = df['WEEKDAY'].apply(lambda x : 1 if x in range(6, 8) else 0 ) # apply to trainset\n",
    "    \n",
    "    # Weekday One Hot Encode\n",
    "    weekday_dummies = pd.get_dummies(df['WEEKDAY'])\n",
    "    weekday_columns = ['WEEKDAY_' + str(i) for i in range(1,8)]\n",
    "    weekday_dummies.columns = weekday_columns\n",
    "    for i in weekday_dummies.columns:\n",
    "        df[i] = weekday_dummies[i]\n",
    "    \n",
    "    return df\n",
    "\n",
    "def get_year(value):\n",
    "    if (np.isnan(value)):\n",
    "        return 'None'\n",
    "    else:\n",
    "        return str(int(pd.to_datetime(value, format = \"%Y%m%d\").year))\n",
    "\n",
    "def get_month(value):\n",
    "    if (np.isnan(value)):\n",
    "        return 'None'\n",
    "    else:\n",
    "        return str(int(pd.to_datetime(value, format = \"%Y%m%d\").month))\n",
    "\n",
    "def get_day(value):\n",
    "    if (np.isnan(value)):\n",
    "        return 'None'\n",
    "    else:\n",
    "        return str(int(pd.to_datetime(value, format = \"%Y%m%d\").day))\n",
    "    \n",
    "def get_weekday(value):\n",
    "    if (np.isnan(value)):\n",
    "        return value\n",
    "    else:\n",
    "        return pd.to_datetime(value, format = \"%Y%m%d\").dayofweek+1 # add one to make it from 0~6 -> 1~7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data\n",
    "dfoff = expand_date_received(dfoff)\n",
    "dfoff.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create target label \n",
    "\"\"\"\n",
    "According to the definition, \n",
    "1) buy with coupon within (include) 15 days ==> 1\n",
    "2) buy with coupon but out of 15 days ==> 0\n",
    "3) buy without coupon ==> -1 (we don't care)\n",
    "\"\"\"\n",
    "def find_label(row):\n",
    "    if np.isnan(row['Date_received']):\n",
    "        return -1\n",
    "    if not np.isnan(row['Date']):\n",
    "        td = pd.to_datetime(row['Date'], format='%Y%m%d') -  pd.to_datetime(row['Date_received'], format='%Y%m%d')\n",
    "        if td <= pd.Timedelta(15, 'D'):\n",
    "            return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_id</th>\n",
       "      <th>Merchant_id</th>\n",
       "      <th>Coupon_id</th>\n",
       "      <th>Discount_rate</th>\n",
       "      <th>Distance</th>\n",
       "      <th>Date_received</th>\n",
       "      <th>Date</th>\n",
       "      <th>LABEL</th>\n",
       "      <th>DISCOUNT_RATE</th>\n",
       "      <th>DISCOUNT_TYPE</th>\n",
       "      <th>...</th>\n",
       "      <th>DISCOUNT_OFF</th>\n",
       "      <th>WEEKDAY</th>\n",
       "      <th>WEEKEND</th>\n",
       "      <th>WEEKDAY_1</th>\n",
       "      <th>WEEKDAY_2</th>\n",
       "      <th>WEEKDAY_3</th>\n",
       "      <th>WEEKDAY_4</th>\n",
       "      <th>WEEKDAY_5</th>\n",
       "      <th>WEEKDAY_6</th>\n",
       "      <th>WEEKDAY_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1439408</td>\n",
       "      <td>2632</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20160217.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1439408</td>\n",
       "      <td>2632</td>\n",
       "      <td>8591.0</td>\n",
       "      <td>20:1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20160217.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1439408</td>\n",
       "      <td>2632</td>\n",
       "      <td>1078.0</td>\n",
       "      <td>20:1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20160319.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1832624</td>\n",
       "      <td>3381</td>\n",
       "      <td>7610.0</td>\n",
       "      <td>200:20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20160429.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2029232</td>\n",
       "      <td>3381</td>\n",
       "      <td>11951.0</td>\n",
       "      <td>200:20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160129.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2223968</td>\n",
       "      <td>3381</td>\n",
       "      <td>9776.0</td>\n",
       "      <td>10:5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20160129.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>73611</td>\n",
       "      <td>2099</td>\n",
       "      <td>12034.0</td>\n",
       "      <td>100:10</td>\n",
       "      <td>99.0</td>\n",
       "      <td>20160207.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>163606</td>\n",
       "      <td>1569</td>\n",
       "      <td>5054.0</td>\n",
       "      <td>200:30</td>\n",
       "      <td>10.0</td>\n",
       "      <td>20160421.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.85</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>30</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3273056</td>\n",
       "      <td>4833</td>\n",
       "      <td>7802.0</td>\n",
       "      <td>200:20</td>\n",
       "      <td>10.0</td>\n",
       "      <td>20160130.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>94107</td>\n",
       "      <td>3381</td>\n",
       "      <td>7610.0</td>\n",
       "      <td>200:20</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20160412.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   User_id  Merchant_id  Coupon_id Discount_rate  Distance  Date_received  \\\n",
       "0  1439408         2632        NaN           NaN       0.0            NaN   \n",
       "1  1439408         2632     8591.0          20:1       0.0     20160217.0   \n",
       "2  1439408         2632     1078.0          20:1       0.0     20160319.0   \n",
       "3  1832624         3381     7610.0        200:20       0.0     20160429.0   \n",
       "4  2029232         3381    11951.0        200:20       1.0     20160129.0   \n",
       "5  2223968         3381     9776.0          10:5       2.0     20160129.0   \n",
       "6    73611         2099    12034.0        100:10      99.0     20160207.0   \n",
       "7   163606         1569     5054.0        200:30      10.0     20160421.0   \n",
       "8  3273056         4833     7802.0        200:20      10.0     20160130.0   \n",
       "9    94107         3381     7610.0        200:20       2.0     20160412.0   \n",
       "\n",
       "         Date  LABEL  DISCOUNT_RATE DISCOUNT_TYPE  ...  DISCOUNT_OFF  WEEKDAY  \\\n",
       "0  20160217.0     -1           1.00          None  ...             0      NaN   \n",
       "1         NaN      0           0.95             1  ...             1      3.0   \n",
       "2         NaN      0           0.95             1  ...             1      6.0   \n",
       "3         NaN      0           0.90             1  ...            20      5.0   \n",
       "4         NaN      0           0.90             1  ...            20      5.0   \n",
       "5         NaN      0           0.50             1  ...             5      5.0   \n",
       "6         NaN      0           0.90             1  ...            10      7.0   \n",
       "7         NaN      0           0.85             1  ...            30      4.0   \n",
       "8         NaN      0           0.90             1  ...            20      6.0   \n",
       "9         NaN      0           0.90             1  ...            20      2.0   \n",
       "\n",
       "   WEEKEND  WEEKDAY_1  WEEKDAY_2  WEEKDAY_3  WEEKDAY_4  WEEKDAY_5  WEEKDAY_6  \\\n",
       "0        0          0          0          0          0          0          0   \n",
       "1        0          0          0          1          0          0          0   \n",
       "2        1          0          0          0          0          0          1   \n",
       "3        1          0          0          0          0          1          0   \n",
       "4        1          0          0          0          0          1          0   \n",
       "5        1          0          0          0          0          1          0   \n",
       "6        1          0          0          0          0          0          0   \n",
       "7        0          0          0          0          1          0          0   \n",
       "8        1          0          0          0          0          0          1   \n",
       "9        0          0          1          0          0          0          0   \n",
       "\n",
       "   WEEKDAY_7  \n",
       "0          0  \n",
       "1          0  \n",
       "2          0  \n",
       "3          0  \n",
       "4          0  \n",
       "5          0  \n",
       "6          1  \n",
       "7          0  \n",
       "8          0  \n",
       "9          0  \n",
       "\n",
       "[10 rows x 21 columns]"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check data\n",
    "dfoff[\"LABEL\"] = dfoff.apply(find_label, axis=1)\n",
    "dfoff.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processData(df):\n",
    "    df = df.copy()\n",
    "    df = trans_id_to_string(df)\n",
    "    df = convert_distance(df)\n",
    "    df = expand_date_received(df)\n",
    "    df['DISCOUNT_RATE'] = df['Discount_rate'].astype('str').apply(convert_rate)\n",
    "    df['DISCOUNT_TYPE'] = df['Discount_rate'].astype('str').apply(find_discount_type)\n",
    "    df['DISCOUNT_REQUIRE'] = df['Discount_rate'].astype('str').apply(find_discount_require)\n",
    "    df['DISCOUNT_OFF'] = df['Discount_rate'].astype('str').apply(find_discount_off)\n",
    "    return df    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = ['USER_ID', 'MERCHANT_ID', 'COUPON_ID',\n",
    "            'Distance',\n",
    "            'DISCOUNT_RATE',\n",
    "            'DISCOUNT_TYPE',\n",
    "            'DISCOUNT_REQUIRE', \n",
    "            'DISCOUNT_OFF',\n",
    "            'YEAR', 'MONTH', 'DAY',\n",
    "            'WEEKEND'] + ['WEEKDAY_' + str(i) for i in range(1,8)]\n",
    "len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make train_X, train_Y, test_X\n",
    "df_train_processed = processData(or_dfoff)\n",
    "df_test_processed = processData(or_dftest)\n",
    "\n",
    "# train set\n",
    "df_train_processed[\"LABEL\"] = df_train_processed.apply(find_label, axis=1)\n",
    "df_train_processed = df_train_processed[df_train_processed['LABEL'] != -1].copy()\n",
    "\n",
    "# test set\n",
    "df_test_processed = df_test_processed[~df_test_processed.Coupon_id.isna()]\n",
    "df_test_processed.reset_index(drop=True, inplace=True)\n",
    "\n",
    "train_X = df_train_processed[features]\n",
    "train_Y = df_train_processed['LABEL']\n",
    "test_X = df_test_processed[features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression AUC : 0.6088564811934012\n"
     ]
    }
   ],
   "source": [
    "estimator = LogisticRegression(C=0.7, fit_intercept = True, n_jobs=-1)\n",
    "print(f'LogisticRegression AUC : {cross_val_score(estimator, train_X, train_Y, cv=5, scoring=\"roc_auc\", n_jobs=-1).mean()}')\n",
    "# print(f'LogisticRegression ACC : {cross_val_score(estimator, train_X, train_Y, cv=5, scoring=\"accuracy\", n_jobs=-1).mean()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier AUC : 0.8769843875533259\n"
     ]
    }
   ],
   "source": [
    "estimator = RandomForestClassifier(\n",
    "    **RF_best_Params\n",
    ")\n",
    "print(f'RandomForestClassifier AUC : {cross_val_score(estimator, train_x, train_y, cv=5, scoring=\"roc_auc\", n_jobs=-1).mean()}')\n",
    "# print(f'RandomForestClassifier ACC : {cross_val_score(estimator, train_X, train_Y, cv=5, scoring=\"accuracy\", n_jobs=-1).mean()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier AUC : 0.8630750144881245\n",
      "GradientBoostingClassifier ACC : 0.9538247862202249\n"
     ]
    }
   ],
   "source": [
    "estimator = GradientBoostingClassifier()\n",
    "print(f'GradientBoostingClassifier AUC : {cross_val_score(estimator, train_X, train_Y, cv=5, scoring=\"roc_auc\", n_jobs=-1).mean()}')\n",
    "# print(f'GradientBoostingClassifier ACC : {cross_val_score(estimator, train_X, train_Y, cv=5, scoring=\"accuracy\", n_jobs=-1).mean()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier AUC : 0.8209401893100662\n",
      "DecisionTreeClassifier ACC : 0.9545142358424143\n"
     ]
    }
   ],
   "source": [
    "################\n",
    "estimator = DecisionTreeClassifier(\n",
    "    criterion='gini',\n",
    "    max_depth=4,\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=1,\n",
    ")\n",
    "print(f'DecisionTreeClassifier AUC : {cross_val_score(estimator, train_X, train_Y, cv=5, scoring=\"roc_auc\", n_jobs=-1).mean()}')\n",
    "print(f'DecisionTreeClassifier ACC : {cross_val_score(estimator, train_X, train_Y, cv=5, scoring=\"accuracy\", n_jobs=-1).mean()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDClassifier AUC : 0.4965069623630047\n",
      "SGDClassifier ACC : 0.9441315090886298\n"
     ]
    }
   ],
   "source": [
    "################\n",
    "estimator = SGDClassifier(\n",
    "    loss='log', \n",
    "    penalty='elasticnet', \n",
    "    fit_intercept=True, \n",
    "    max_iter=100, \n",
    "    shuffle=True, \n",
    "    class_weight=None,\n",
    "    n_jobs=-1\n",
    ")\n",
    "print(f'SGDClassifier AUC : {cross_val_score(estimator, train_X, train_Y, cv=5, scoring=\"roc_auc\", n_jobs=-1).mean()}')\n",
    "print(f'SGDClassifier ACC : {cross_val_score(estimator, train_X, train_Y, cv=5, scoring=\"accuracy\", n_jobs=-1).mean()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Set, Test Set\n",
    "x_train, x_validate, y_train, y_validate = train_test_split(train_X2, train_Y2, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(\n",
    "    n_estimators=100, \n",
    "    criterion='gini',\n",
    "    max_depth=10,\n",
    "    n_jobs=-1\n",
    ")\n",
    "clf.fit(x_train, y_train)\n",
    "y_pred = clf.predict_proba(x_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:  0.8224612306463761\n",
      "Acuuracy:  0.9518588430592929\n"
     ]
    }
   ],
   "source": [
    "auc_score = roc_auc_score(y_validate, y_pred[:,1])\n",
    "print(\"AUC: \", auc_score)\n",
    "acc = accuracy_score(y_validate, y_pred.argmax(axis=1))\n",
    "print(\"Acuuracy: \", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomizedSearchCV\n",
    "from sklearn.model_selection import  RandomizedSearchCV\n",
    "#first we will tune the parameters of every model \n",
    "RFParams = {'n_estimators':np.arange(100,1100,100), 'max_depth':np.arange(3,11,2),\n",
    "            'min_samples_split':np.arange(2,20,2), 'min_samples_leaf':np.arange(1,6,2) }\n",
    "\n",
    "gbcParams = {'n_estimators' : np.arange(100,1100,50) , 'learning_rate' : np.arange(0.01,0.2,0.05) \n",
    "             , 'min_samples_split' : np.arange(2,20,2), 'min_samples_leaf' : np.arange(1,6,2),\n",
    "              'max_depth' : np.arange(3,11,2), 'subsample' : np.arange(0.3,0.8,0.1), 'max_features' : np.arange(5,19,5) }\n",
    "\n",
    "ETParams = {'n_estimators':np.arange(100,1100,50), 'max_depth':np.arange(3,11,2),\n",
    "            'min_samples_leaf':np.arange(1,6,2) }\n",
    "\n",
    "logParams = { 'C' : np.arange(0.1,1.5,0.2) }\n",
    "\n",
    "#We use GridSearchCV to find the best params of the classifier\n",
    "#cv = 5 means we will split data into 5 piece for cross validation.\n",
    "#n_jobs = -1 means we want all the processor to run in parallel (cuz this might take a lot of estimation)\n",
    "def tuneParams(classifier, params, train_x, train_y, cv = 5):\n",
    "    md = GridSearchCV(classifier, params, cv = cv, scoring = 'accuracy', n_jobs = -1)\n",
    "    md.fit(train_x,train_y)\n",
    "\n",
    "    return md.best_params_,np.round(md.best_score_*100,2)\n",
    "\n",
    "def tuneParamsRandom(classifier, params, train_x, train_y, cv=5):\n",
    "    rs = RandomizedSearchCV(classifier, params, n_iter = 30,scoring = 'roc_auc', n_jobs = -1, verbose = 0)\n",
    "    rs.fit(train_x,train_y)\n",
    "    \n",
    "    return rs.best_params_, abs(rs.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will use xgboost, adaBoost, randomForest, ExtraTrees, KNeighbors and SVC to be the classifier of our first step ensemble stacking\n",
    "limit = 100000\n",
    "train_x = train_X[:limit]\n",
    "train_y = train_Y[:limit]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression: {'C': 0.9000000000000001} 0.6691455443130842\n"
     ]
    }
   ],
   "source": [
    "Log_best_Params, Log_best_score = tuneParamsRandom(LogisticRegression(fit_intercept = True, n_jobs=-1), logParams, train_x, train_y)\n",
    "print(\"LogisticRegression:\",Log_best_Params,Log_best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GBC_best_Params,GBC_best_score = tuneParamsRandom(GradientBoostingClassifier(),gbcParams,train_x, train_y)\n",
    "print(\"GradientBoostingClassifier:\",GBC_best_Params,GBC_best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_best_Params,RF_best_score = tuneParamsRandom(RandomForestClassifier(),RFParams,train_x, train_y)\n",
    "print(\"RandomForest:\",RF_best_Params,RF_best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GBC_best_Params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model\n",
    "# lr = LogisticRegression(n_jobs=-1, **Log_best_Params)\n",
    "lr = LogisticRegression(n_jobs=-1, C=0.5000000000000001)\n",
    "rf = RandomForestClassifier(n_jobs=-1, **RF_best_Params)\n",
    "gdbt = GradientBoostingClassifier(**GBC_best_Params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.5000000000000001, class_weight=None, dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='warn', n_jobs=-1, penalty='l2', random_state=None,\n",
       "          solver='warn', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(train_X, train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=9, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=5, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=900, n_jobs=-1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.fit(train_X, train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.01, loss='deviance', max_depth=5,\n",
       "              max_features=5, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=5, min_samples_split=16,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=750,\n",
       "              n_iter_no_change=None, presort='auto', random_state=None,\n",
       "              subsample=0.7000000000000002, tol=0.0001,\n",
       "              validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdbt.fit(train_X, train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StackingClassifier(average_probas=False,\n",
       "          classifiers=[LogisticRegression(C=0.5000000000000001, class_weight=None, dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='warn', n_jobs=-1, penalty='l2', random_state=None,\n",
       "          solver='warn', tol=0.0001, verbose=0, warm_start=False), RandomFor...0.7000000000000002, tol=0.0001,\n",
       "              validation_fraction=0.1, verbose=0, warm_start=False)],\n",
       "          drop_last_proba=False,\n",
       "          meta_classifier=GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.01, loss='deviance', max_depth=5,\n",
       "              max_features=5, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=5, min_s...=0.7000000000000002, tol=0.0001,\n",
       "              validation_fraction=0.1, verbose=0, warm_start=False),\n",
       "          store_train_meta_features=False, use_clones=True,\n",
       "          use_features_in_secondary=False, use_probas=True, verbose=0)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stacking\n",
    "meta_estimator = GradientBoostingClassifier(\n",
    "   **GBC_best_Params\n",
    ")\n",
    "stacking = StackingClassifier(\n",
    "    classifiers=[lr, rf, gdbt], \n",
    "    meta_classifier=meta_estimator,\n",
    "    use_probas=True,\n",
    "    average_probas=False\n",
    ")\n",
    "\n",
    "stacking.fit(train_X, train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: [0.04780471 0.05659403 0.04189387 ... 0.0652087  0.06631522 0.0603904 ]\n",
      "RF: [0.15806528 0.13522656 0.13965397 ... 0.15067735 0.14518953 0.11390748]\n",
      "GDBT: [0.15443492 0.12019053 0.14669518 ... 0.14618367 0.08892432 0.08591443]\n",
      "SK: [0.18249939 0.1559159  0.15187944 ... 0.16194545 0.32905657 0.09648319]\n",
      "BD: [0.1442348  0.11854793 0.13165978 ... 0.13741447 0.13637266 0.08559923]\n"
     ]
    }
   ],
   "source": [
    "# Blending\n",
    "lr_p3_02 = pd.read_csv('LR_P3_02.csv')\n",
    "rf_p3_01 = pd.read_csv('RF_P3_01.csv')\n",
    "gdbt_p3_01 = pd.read_csv('GDBT_P3_01.csv')\n",
    "sk_p3_01 = pd.read_csv('SK_P3_01.csv')\n",
    "\n",
    "lr_pred = lr_p3_02['label'].values\n",
    "rf_pred = rf_p3_01['label'].values\n",
    "gdbt_pred = gdbt_p3_01['label'].values\n",
    "sk_pred = sk_p3_01['label'].values\n",
    "\n",
    "print('LR:', lr_pred)\n",
    "print('RF:', rf_pred)\n",
    "print('GDBT:', gdbt_pred)\n",
    "print('SK:', sk_pred)\n",
    "\n",
    "blending_pred_Y = lr_pred*0.15  + rf_pred*0.05 + gdbt_pred*0.6 + sk_pred*0.2\n",
    "print('BD:', blending_pred_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "bd = lr_p3_02.copy()\n",
    "bd['label'] = blending_pred_Y\n",
    "bd.to_csv(\"BD_P3_05.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000020_2705_20160519</td>\n",
       "      <td>0.182499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000020_8192_20160513</td>\n",
       "      <td>0.155916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000065_1455_20160527</td>\n",
       "      <td>0.151879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000085_8067_20160513</td>\n",
       "      <td>0.067641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000086_2418_20160613</td>\n",
       "      <td>0.100503</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     uid     label\n",
       "0  1000020_2705_20160519  0.182499\n",
       "1  1000020_8192_20160513  0.155916\n",
       "2  1000065_1455_20160527  0.151879\n",
       "3  1000085_8067_20160513  0.067641\n",
       "4  1000086_2418_20160613  0.100503"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict and write to file\n",
    "pred_Y = stacking.predict_proba(test_X)\n",
    "\n",
    "df_test_processed['pred_prob'] = pred_Y[:, 1]\n",
    "output = pd.concat((df_test_processed[[\"User_id\", \"Coupon_id\", \"Date_received\"]], df_test_processed['pred_prob']), axis=1)\n",
    "\n",
    "output.loc[:, \"User_id\"] = output[\"User_id\"].apply(lambda x:str(int(x)))\n",
    "output.loc[:, \"Coupon_id\"] = output[\"Coupon_id\"].apply(lambda x:str(int(x)))\n",
    "output.loc[:, \"Date_received\"] = output[\"Date_received\"].apply(lambda x:str(int(x)))\n",
    "output[\"uid\"] = output[[\"User_id\", \"Coupon_id\", \"Date_received\"]].apply(lambda x: '_'.join(x.values), axis=1)\n",
    "output.reset_index(drop=True, inplace=True)\n",
    "\n",
    "out = output.groupby(\"uid\", as_index=False).mean()\n",
    "out = out[[\"uid\", \"pred_prob\"]]\n",
    "out.columns = [\"uid\", \"label\"]\n",
    "out.to_csv(\"SK_P3_01.csv\", header=[\"uid\", \"label\"], index=False) # submission format\n",
    "out.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
